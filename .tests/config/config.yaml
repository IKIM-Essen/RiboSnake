# This file should contain everything to configure the workflow on a global scale.
# In case of sample based data, it should be complemented by a samples.tsv file that contains
# one row per sample. It can be parsed easily via pandas.
pepfile: config/pep/config.yaml

# If testing set true
testing: True
# If data-preparation should be enabled
include-data-prep: False
# Modus: If true, analysis will be done with DADA2 instead of vsearch
DADA2: False
# Longitudinal analysis, for further parameters look at line 204 of this document
longitudinal: False
# Shorter analysis for small number of samples or samples without metadata
reduced-analysis: False
# Whether to use bowtie2 for excluding human host contamination or not
bowtie: False
# Set if environmental or human data is processed
data-type: environmental
# Paths to the directories holding the fastqs
input: ../incoming/
data: data/
output: ../report/
# Path to the sheet holding metadata information
metadata: config/pep/metadata.txt
# Remove columns from analysis
remove-columns: ["site_name"]
# Paths to the databases used for classification and taxonomy
database:
  Silva: True 
  download-path-seq: resources/silva-138-99-seqs.qza
  download-path-tax: resources/silva-138-99-tax.qza
  kraken-db: ftp://ftp.ccb.jhu.edu/pub/data/kraken2_dbs/old/minikraken2_v2_8GB_201904.tgz
  ref-genome: https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh38_latest/refseq_identifiers/GRCh38_latest_genomic.fna.gz
  Greengenes: False 
  gg2-seq: http://ftp.microbio.me/greengenes_release/current/2022.10.backbone.full-length.fna.qza
  gg2-tax: http://ftp.microbio.me/greengenes_release/current/2022.10.backbone.tax.qza
  NCBI: False
  NCBI-query: 33175[BioProject]
# Forward and reverse adapters used for sequencing
adapter1: TCGTCGGCAGCGTCAGATGTGTATAAGAGACAG
adapter2: GTCTCGTGGGCTCGGAGATGTGTATAAGAGACAG
# Type of data, single-end: 'SampleData[SequencesWithQuality]' or paired-end: 'SampleData[PairedEndSequencesWithQuality]'
datatype: 'SampleData[PairedEndSequencesWithQuality]'
#Primertrimming parameters
primertrimming:
  forward: CCTACGGGNGGCWGCAG
  reverse: GACTACHVGGGTATCTAATCC
  # Maximum allowed error rate
  error_rate: 0.1
  # Remove multiple occurrences of an adapter if it is repeated, up to `times` times
  rep_times: 1
  # Require at least `overlap` bases of overlap between read and adapter for an adapter to be found
  overlap: 3
  # Discard reads shorter than specified value
  min_length: 6
sequence_joining:
  # Minimum overlap length of forward and reverse reads for joining.
  seq_join_length: 30
  # Sequences shorter than minlen after truncation are discarded. 
  minlen: 1
  # Maximum number of mismatches in the forward/reverse read overlap for joining. 
  maxdiffs: 10
  # The minimum allowed quality score in the input.
  qmin: 0
  # The minimum allowed quality score to use in output.
  qminout: 0
  # The maximum allowed quality score in the input.
  qmax: 41
  # The maximum allowed quality score to use in output.
  qmaxout: 41
  # Number of threads to use
  threads: 1
# Threads to be used by the different methods
threads: 1
# Parameters necessary for filtering
filtering:
  # Relative threshold for the abundance filtering
  relative-abundance-filter: 0.001
  # Minimum length of a sequence to be retained
  min-seq-length: 200
  # Minimum quality score for sequences to pass filter
  phred-score: 20
  # Maximum number of undetermined base calls ("N")
  max-ambiguity: 50
  # The minimum length that a sequence read can be following truncation and still be retained
  min-length-frac: 0.75
  # Increasing this value tends to reduce the number of false positives and to decrease sensitivity.
  chimera-minh: 0.35
  # Percentual identity between query sequence and reference human genome
  perc-identity: 0.93
  # Percent of query sequence that must align to reference in order to be accepted as a hit
  perc-query-aligned: 0.93
# Parameters for plots
metadata-parameters:
  taxa-heatmap-column: extract_group_no
  beta-metadata-column: extract_group_no
  gneiss-metadata-column: site_name
  absolute-taxa-name: extract_group_no
  # Specify which axes to cluster: ('features', 'samples', 'both', 'none')
  cluster: features
# Parameters for classification
classification:
  # Reject match if percent identity to query is lower
  perc-identity: 0.97
  # Range (1,None), String("all"), Maximum number of hits to keep for each query
  maxaccepts: 1
  # Range(1,None), String("all"), Maximum number of non-matching target sequences to consider before stopping the search
  maxrejects: 1
  # Reject match if query alignment coverage per high-scoring pair is lower. 
  query-cov: 0.8
  # Minimum fraction of assignments must match top hit to be accepted as consensus assignment.
  min-consensus: 0.51
# Parameters for de-novo clustering with vsearch
clustering:
  #The percent identity at which clustering should be performed
  perc-identity: 0.99
# Parameters set for alpha- and beta-rarefaction
rarefaction:
  # The maximum rarefaction depth. Must be greater than min-depth
  max-depth: 400
  # The total frequency that each sample should be rarefied to prior to computing the diversity metric
  sampling_depth: 100
  # How often rarefaction should be repeated
  repeats: 50
  # The beta diversity metric to be computed
  metric: euclidean
  # Samples can be clustered with neighbor joining or UPGMA ("nj", "upgma")
  clustering_method: nj
# Parameters for diversity analysis
diversity:
  # Parameters for alpha-diversity analysis
  alpha:
    # Metric to be computed
    diversity-metric: ["pielou_e"]
    # Metric to be computed
    phylogeny-metric: ["faith_pd"]
    # Alpha-correlation method
    correlation-method: 'spearman'
  # Parameters for beta-diversity analysis
  beta:
    # Metric to be computed
    diversity-metric: ["euclidean"]
    # A pseudocount to handle zeros for compositional metrics
    diversity-pseudocount: 1
    # The number of concurrent jobs to use in performing this calculation
    diversity-n-jobs: 1
    # Correlation test to be applied ('spearman', 'pearson')
    correlation-method: 'spearman'
    # The number of permutations to be run when computing p-values
    correlation-permutations: 999
    # The beta diversity metric to be computed ('weighted_normalized_unifrac',
    # 'generalized_unifrac', 'weighted_unifrac', 'unweighted_unifrac')
    phylogeny-metric: ['weighted_normalized_unifrac']
    # Perform variance adjustment based on Chang et al. BMC Bioinformatics 2011
    phylogeny-variance-adjusted: True
# If DADA2 is set to true, these parameters are used for denoising and clustering paired-end-data with DADA2
dada2-paired:
  # Position at which forward reads should be truncated at the 3' end due to low quality
  trunc-len-f: 240
  # Position at which reverse reads should be truncated at the 3' end due to low quality
  trunc-len-r: 240
  # Position at which forward reads should be truncated at the 5' end due to low quality
  trim-left-f: 0
  # Position at which reverse reads should be truncated at the 5' end due to low quality
  trim-left-r: 0
  # Forward reads with number of expected errors higher than this value will be discarded
  max-ee-f: 2.0
  # Reverse reads with number of expected errors higher than this value will be discarded.
  max-ee-r: 2.0
  # Reads are truncated at the first instance of a quality score less than or equal to this value
  trunc-q: 5
  # The minimum length of the overlap required for merging the forward and reverse reads
  min-overlap: 12
  # The method used to pool samples for denoising ('independent', 'pseudo')
  pooling-method: 'independent'
  # The method used to remove chimeras ('none', 'consensus', 'pooled')
  chimera-method: 'consensus'
  # The minimum abundance of potential parents of a sequence being tested as chimeric, expressed as a 
  # fold-change versus the abundance of the sequence being tested
  min-fold-parent-over-abundance: 1.0
  # The number of reads to use when training the errormodel
  n-reads-learn: 1000000
# If DADA2 is set to true, these parameters are used for denoising and clustering single-end-data with DADA2
dada2-single:
  # Position at which reads should be truncated at the 3' end due to low quality
  trunc-len: 240
  # Position at which reads should be truncated at the 5' end due to low quality
  trim-left: 10
  # Reads with number of expected errors higher than this value will be discarded
  max-ee: 2.0
  # Reads are truncated at the first instance of a quality score less than or equal to this value
  trunc-q: 5
  # The method used to pool samples for denoising ('independent', 'pseudo')
  pooling-method: 'independent'
  # The method used to remove chimeras ('none', 'consensus', 'pooled')
  chimera-method: 'consensus'
  # The minimum abundance of potential parents of a sequence being tested as chimeric, expressed as a 
  # fold-change versus the abundance of the sequence being tested
  min-fold-parent-over-abundance: 1.0
  # The number of reads to use when training the errormodel
  n-reads-learn: 1000000
# Creating rankings for feature impact on specific metadata
songbird:
  # Specifies the width of the prior distribution of the differentials
  differential_prior: 0.5
  # Number at which sample with a smaller occurance should be filtered out
  min_sample_count: 0
  # Number at which features with a smaller occurance should be filtered out
  min_feature_count: 0
  # Impacts how often a "measurement" is taken for these plots
  summary_interval: 1
  # Formula
  formula: "toc"
# Feature classification with ancom
ancom:
  # Catgorical metadata column to analyse
  metadata-column: ["extract_group_no"]
# Parameters for longitudinal analysis, used when longitudinal is set to True
longitudinal-params:
  # Column with continuous data to use primarily
  state_column: "average_soil_temperature"
  # Column to name the samples
  individual_id_column: "sample_name"
  # Formula for linear-mixed-effect analysis
  metric: extraction_date
